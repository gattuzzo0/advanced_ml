{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 1a: Implementing a Multilayer Fully Connected Network using Numpy\n",
    "#### Non-graded activity (0 points)\n",
    "\n",
    "- Objective\n",
    "\n",
    "The primary objective of this activity is to deepen your understanding of Fully Connected Networks by implementing a multilayer network using only Numpy. You  are  given  the follosing starter code that solves the MNIST dataset problem. Your task is to read, understand, and then apply this knowledge to solve classification problems on other datasets such as the Kaggle ASL dataset (Starter code will be provided separately for that activity).\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    Read and Understand the following Code: The provided starter code outlines the architecture of a Fully Connected Network designed to classify MNIST images. Go through the code to understand how each function and class is used to implement the network.\n",
    "\n",
    "    Understand the Math: Make sure you understand the math operations implemented in the code, especially during the forward and backward passes. This will involve matrix multiplications, activation functions, loss computations, and backpropagation.\n",
    "    \n",
    "- Experiment\n",
    "    You are encouraged to play with the code, change any hyperparameters and train the model, you should be able to achieve over 95% accuracy on the test set without problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rog1slp\\.conda\\envs\\master_advanced_ml\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\rog1slp\\.conda\\envs\\master_advanced_ml\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\rog1slp\\.conda\\envs\\master_advanced_ml\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_images import get_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST path\n",
    "mnist_path = './mnist_raw/'\n",
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
    "\n",
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(float)\n",
    "y_train = y_train_num[:50000].reshape(50000, 1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(float)\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(float)\n",
    "y_test = y_test_num.copy().reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.38638106, -0.19570196, -0.19570196,\n",
       "       -0.19570196,  1.17718759,  1.30430699,  1.80007266, -0.09400644,\n",
       "        1.6856652 ,  2.81702788,  2.71533236,  1.18989953, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.04315868,  0.03311297,  0.7704055 ,  1.53312192,\n",
       "        1.73651296,  2.791604  ,  2.791604  ,  2.791604  ,  2.791604  ,\n",
       "        2.791604  ,  2.43566968,  1.76193684,  2.791604  ,  2.65177266,\n",
       "        2.05431147,  0.38904729, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688,  0.19836819,  2.6009249 ,\n",
       "        2.791604  ,  2.791604  ,  2.791604  ,  2.791604  ,  2.791604  ,\n",
       "        2.791604  ,  2.791604  ,  2.791604  ,  2.76618012,  0.75769356,\n",
       "        0.61786222,  0.61786222,  0.28735177,  0.07124879, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.19570196,  2.35939804,  2.791604  ,  2.791604  ,\n",
       "        2.791604  ,  2.791604  ,  2.791604  ,  2.09244729,  1.88905625,\n",
       "        2.71533236,  2.63906072, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "        0.59243834,  1.5585458 ,  0.93566073,  2.791604  ,  2.791604  ,\n",
       "        2.18143087, -0.28468554, -0.42451688,  0.12209655,  1.53312192,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.24654972,\n",
       "       -0.41180494,  1.53312192,  2.791604  ,  0.71955774, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688,  1.34244281,\n",
       "        2.791604  ,  1.99075177, -0.399093  , -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.28468554,  1.99075177,  2.791604  ,\n",
       "        0.46531894, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688,  0.02040103,  2.63906072,  2.43566968,  1.60939356,\n",
       "        0.94837267, -0.41180494, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "        0.60515028,  2.62634878,  2.791604  ,  2.791604  ,  1.08820401,\n",
       "       -0.10671838, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688,  0.14752043,\n",
       "        1.93990401,  2.791604  ,  2.791604  ,  1.48227416, -0.0812945 ,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.22112584,  0.75769356,\n",
       "        2.77889206,  2.791604  ,  1.95261595, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688,  2.74075624,  2.791604  ,\n",
       "        2.74075624,  0.38904729, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688,  0.16023237,  1.22803535,\n",
       "        1.90176819,  2.791604  ,  2.791604  ,  2.20685475, -0.399093  ,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688,  0.07124879,\n",
       "        1.45685028,  2.48651744,  2.791604  ,  2.791604  ,  2.791604  ,\n",
       "        2.75346818,  1.88905625, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.11943032,  1.02464431,  2.38482192,  2.791604  ,  2.791604  ,\n",
       "        2.791604  ,  2.791604  ,  2.13058311,  0.56701446, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.13214226,  0.41447117,  2.28312639,  2.791604  ,\n",
       "        2.791604  ,  2.791604  ,  2.791604  ,  2.09244729,  0.60515028,\n",
       "       -0.399093  , -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.19570196,  1.7492249 ,  2.35939804,\n",
       "        2.791604  ,  2.791604  ,  2.791604  ,  2.791604  ,  2.05431147,\n",
       "        0.59243834, -0.31010942, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688,  0.27463983,  1.76193684,\n",
       "        2.44838162,  2.791604  ,  2.791604  ,  2.791604  ,  2.791604  ,\n",
       "        2.67719654,  1.26617117, -0.28468554, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688,  1.30430699,  2.791604  ,  2.791604  ,  2.791604  ,\n",
       "        2.27041445,  1.29159505,  1.25345923, -0.22112584, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688, -0.42451688,\n",
       "       -0.42451688, -0.42451688, -0.42451688, -0.42451688])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.39512885204082, 78.6661972212754, 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9.646705203355238e-18, 0.9999999999999997)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: 0\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equations\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creat Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]  \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class np_tensor(np.ndarray): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 0])\n",
    "b = a.view(np_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.np_tensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np_tensor([ True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a is b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clase Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Init parameters utilizando Kaiming He\n",
    "        '''\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "    def __call__(self, X): # esta el foward de la clase lineal\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z\n",
    "    def backward(self, X, Z):\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    def backward(self, Z, A):\n",
    "        Z.grad = A.grad.copy()\n",
    "        Z.grad[Z <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "    def __call__(self, X):\n",
    "        self.x = X \n",
    "        self.outputs['l0'] = self.x\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            self.x = layer(self.x)\n",
    "            self.outputs['l'+str(i)]=self.x\n",
    "        return self.x\n",
    "    def backward(self):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
    "    def update(self, learning_rate = 1e-3):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ReLU): continue\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.__call__(X))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    batch_size = x.shape[1]\n",
    "    exp_scores = np.exp(x)\n",
    "    probs = exp_scores / exp_scores.sum(axis = 0)\n",
    "    preds = probs.copy()\n",
    "    # Costo\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    # Calcular gradientes\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #dl/dx\n",
    "    x.grad = probs.copy()\n",
    "    \n",
    "    return preds, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores = model(x.T.view(np_tensor))\n",
    "            _, cost = softmaxXEntropy(scores, y)\n",
    "            model.backward()\n",
    "            model.update(learning_rate)\n",
    "        print(f'costo: {cost}, accuracy: {accuracy(x_val, y_val, mb_size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def accuracy(x, y, mb_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
    "        pred = model(x.T.view(np_tensor))\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
    "        total += pred.shape[1]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 10)])\n",
    "mb_size = 1024\n",
    "learning_rate = 0.0001\n",
    "epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo: 0.3008616232884464, accuracy: 0.9118\n",
      "costo: 0.21171171842344194, accuracy: 0.9333\n",
      "costo: 0.21294271088974864, accuracy: 0.9445\n",
      "costo: 0.1813291887896634, accuracy: 0.9503\n",
      "costo: 0.17770974122819383, accuracy: 0.9557\n",
      "costo: 0.14571066217957418, accuracy: 0.959\n",
      "costo: 0.13866890515829458, accuracy: 0.9599\n",
      "costo: 0.1276819831622216, accuracy: 0.9631\n",
      "costo: 0.1093243466101665, accuracy: 0.965\n",
      "costo: 0.09910819313780435, accuracy: 0.9653\n",
      "costo: 0.09449497566445766, accuracy: 0.9674\n",
      "costo: 0.11381762532235659, accuracy: 0.969\n",
      "costo: 0.0767059377101954, accuracy: 0.9693\n",
      "costo: 0.06734391625128114, accuracy: 0.971\n",
      "costo: 0.05150351586709508, accuracy: 0.971\n",
      "costo: 0.09562027107897472, accuracy: 0.9717\n",
      "costo: 0.0748064344551375, accuracy: 0.9717\n",
      "costo: 0.06629995919631251, accuracy: 0.9735\n",
      "costo: 0.055833634346678256, accuracy: 0.9728\n",
      "costo: 0.05582541459949748, accuracy: 0.9732\n",
      "costo: 0.05308175888273316, accuracy: 0.9743\n",
      "costo: 0.03953143824901905, accuracy: 0.9733\n",
      "costo: 0.0384293449319509, accuracy: 0.9749\n",
      "costo: 0.03381323617129394, accuracy: 0.9749\n",
      "costo: 0.035962574671897715, accuracy: 0.9748\n",
      "costo: 0.05490540436649528, accuracy: 0.9752\n",
      "costo: 0.031247041172191577, accuracy: 0.9758\n",
      "costo: 0.02614981247249417, accuracy: 0.9753\n",
      "costo: 0.031845789435595497, accuracy: 0.9754\n",
      "costo: 0.041343791522149315, accuracy: 0.9749\n",
      "costo: 0.03547793504434914, accuracy: 0.9759\n",
      "costo: 0.034756402833637096, accuracy: 0.9754\n",
      "costo: 0.034111851405735735, accuracy: 0.9753\n",
      "costo: 0.03198772833294973, accuracy: 0.9754\n",
      "costo: 0.030446022418015237, accuracy: 0.976\n",
      "costo: 0.02063562652606255, accuracy: 0.975\n",
      "costo: 0.02510333841305225, accuracy: 0.9756\n",
      "costo: 0.02622534939960937, accuracy: 0.9764\n",
      "costo: 0.015683018785631754, accuracy: 0.976\n",
      "costo: 0.018669945676887862, accuracy: 0.9763\n",
      "costo: 0.03312042557494905, accuracy: 0.976\n",
      "costo: 0.016289043849378324, accuracy: 0.9763\n",
      "costo: 0.020966730319446836, accuracy: 0.9779\n",
      "costo: 0.01905890720637576, accuracy: 0.9764\n",
      "costo: 0.025132880524429024, accuracy: 0.9756\n",
      "costo: 0.013712544597619612, accuracy: 0.9774\n",
      "costo: 0.01516702702709093, accuracy: 0.9761\n",
      "costo: 0.01148430672961653, accuracy: 0.9772\n",
      "costo: 0.013178145643675115, accuracy: 0.9765\n",
      "costo: 0.011942263198080083, accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9774\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(x_test, y_test, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAGVCAYAAADZmQcFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAKnElEQVR4nO3cX2jV9R/H8XNk2UW4LgzGnEoMIiToIroZLDIXxjBE7KqbCBGHsosgAr3qpgshBfHGzTsvvJHQixFe+A+8Kb1YpaCEILaCocMLF0RF2/lddNefn/u+e+3M1eNxfV58Pkzwyffm0+50Op0WAPxDa1b6AgD8OwgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARPQs9Yftdns57wHAE2wpj6r4QgEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiOhZ6QvAavDRRx+Vdp988klpd/PmzdJueHi48ebnn38unQV/5AsFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAivDbNqPfXUU6Xd0aNHG2/ee++90lnVO/b395d2zz33XOPNDz/8UDoL/sgXCgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAES0O51OZ0k/bLeX+y7QyPr160u7ubm58E2eHJcuXWq8efvtt0tn/fLLL6Udq9NSUuELBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIrw2z4p599tnSbmpqqrQbHh5uvHn06FHprMOHD5d2hw4dKu16e3sbby5fvlw6a/fu3aXd/Px8acfK8towAF0jKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABDRs9IXgPHx8dKu8mpw1Z49e0q7c+fOlXbT09Ol3ZkzZxpvtm3bVjpr3759pd2RI0dKO558vlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiGh3Op3Okn7Ybi/3XXiCVP69jx07VjprbGystFu7dm1pNzEx0XjzwQcflM769ddfS7tNmzaVdl9++WXjTX9/f+msu3fvlnavvfZaaTc7O1vakbGUVPhCASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAiPQ/KX9u7d23hz8uTJZbjJ37tz505p9+KLL4ZvktfX11faffjhh403o6OjpbNeeuml0m5ycrK0279/f2lHhschAegaQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIrw3zl77//vvGm4GBga6d1Wq1Wtu3by/tvv3229Lu32rjxo2l3czMTGl3//790m7Tpk2NN7/99lvpLP7Ma8MAdI2gABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQETPSl+A5fXOO++Udv39/eGb/L0rV66Udl4NzpidnS3tPv/889Jux44dpd34+HjjzbFjx0pnUeMLBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYCIdqfT6Szph+32ct+F/+PVV18t7aampkq7vr6+xpvr16+Xztq5c2dp9+DBg9KOjBMnTpR2Y2Njpd29e/cabwYHB0tn8WdLSYUvFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIjwOGSXrVlTa/iFCxdKuzfeeKO0W1hYaLwZGRkpnXX16tXSjpXV29tb2n311VelXeX/II9D5ngcEoCuERQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACI6FnpC/zXHDhwoLSrvhpcdfjw4cYbrwb/t8zPz5d2P/30U2n3zDPPlHZ0jy8UACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACK8NtxlO3fu7Op5Dx8+LO2OHz8evgn8bnZ2trQbGhpqvHnllVdKZ01PT5d2/3W+UACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACI8Npwl73wwgtdPW9iYqK0m5ubC98Efnf27NnS7s0332y82bBhQ+ksrw3X+EIBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACI9D/gOjo6ONN5s3b16Gm/y9y5cvd/U8eJyhoaHS7rvvvmu8OX/+fOksanyhABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABDhteF/oKen+Z9vzZpawzudTmm3cePG0g4ep/LadqvVau3atau0++abbxpvFhYWSmdR4wsFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgIh2Z4nP2Lbb7eW+y6qzbt26xptbt26VzhoYGCjtvv7669Ju//79jTfXrl0rncXKGhkZKe3Onj1b2s3MzJR227Zta7yZm5srncWfLSUVvlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiPDacJft27evtPv0009Lu8qLyK1Wq7W4uNiVTavVan322Wel3dTUVGn3xRdfNN78+OOPpbOqf/+qd999t/Hm448/Lp1V/fd+//33S7szZ86UdmR4bRiArhEUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgwuOQq8TWrVtLu4MHD5Z2r7/+euPN008/XTprNbh3715p9/zzz0fvsRwuXrxY2p06daq0O336dGnHyvI4JABdIygARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQ4bVh/tLg4GDjzVtvvVU6a8uWLaVdVV9fX+PNyy+/XDrr/v37pd2NGzdKu9u3bzfeTE5Ols5aXFws7VidvDYMQNcICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAER4bRiAx/LaMABdIygARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARPQs9YedTmc57wHAKucLBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEBYCI/wE9VmyBLv2KmAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor predicho es: 0, el valor real es:0\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {pred}, el valor real es:{y_test[idx][0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
