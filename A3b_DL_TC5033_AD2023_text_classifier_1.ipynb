{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gattuzzo0/advanced_ml/blob/main/A3b_DL_TC5033_AD2023_text_classifier_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "940c6dbc",
      "metadata": {
        "id": "940c6dbc"
      },
      "source": [
        "## TC 5033\n",
        "### Word Embeddings\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Activity 3b: Text Classification using RNNs and AG_NEWS dataset in PyTorch\n",
        "<br>\n",
        "\n",
        "- Objective:\n",
        "    - Understand the basics of Recurrent Neural Networks (RNNs) and their application in text classification.\n",
        "    - Learn how to handle a real-world text dataset, AG_NEWS, in PyTorch.\n",
        "    - Gain hands-on experience in defining, training, and evaluating a text classification model in PyTorch.\n",
        "    \n",
        "<br>\n",
        "\n",
        "- Instructions:\n",
        "    - Data Preparation: Starter code will be provided that loads the AG_NEWS dataset and prepares it for training. Do not modify this part. However, you should be sure to understand it, and comment it, the use of markdown cells is suggested.\n",
        "\n",
        "    - Model Setup: A skeleton code for the RNN model class will be provided. Complete this class and use it to instantiate your model.\n",
        "\n",
        "    - Implementing Accuracy Function: Write a function that takes model predictions and ground truth labels as input and returns the model's accuracy.\n",
        "\n",
        "    - Training Function: Implement a function that performs training on the given model using the AG_NEWS dataset. Your model should achieve an accuracy of at least 80% to get full marks for this part.\n",
        "\n",
        "    - Text Sampling: Write a function that takes a sample text as input and classifies it using your trained model.\n",
        "\n",
        "    - Confusion Matrix: Implement a function to display the confusion matrix for your model on the test data.\n",
        "\n",
        "    - Submission: Submit your completed Jupyter Notebook. Make sure to include a markdown cell at the beginning of the notebook that lists the names of all team members. Teams should consist of 3 to 4 members.\n",
        "    \n",
        "<br>\n",
        "\n",
        "- Evaluation Criteria:\n",
        "\n",
        "    - Correct setup of all the required libraries and modules (10%)\n",
        "    - Code Quality (30%): Your code should be well-organized, clearly commented, and easy to follow. Use also markdown cells for clarity. Comments should be given for all the provided code, this will help you understand its functionality.\n",
        "    \n",
        "   - Functionality (60%):\n",
        "        - All the functions should execute without errors and provide the expected outputs.\n",
        "        - RNN model class (20%)\n",
        "        - Accuracy fucntion (10%)\n",
        "        - Training function (10%)\n",
        "        - Sampling function (10%)\n",
        "        - Confucion matrix (10%)\n",
        "\n",
        "        - The model should achieve at least an 80% accuracy on the AG_NEWS test set for full marks in this criterion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4de318da",
      "metadata": {
        "id": "4de318da"
      },
      "source": [
        "Dataset\n",
        "\n",
        "https://pytorch.org/text/stable/datasets.html#text-classification\n",
        "\n",
        "https://paperswithcode.com/dataset/ag-news\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a9801f9",
      "metadata": {
        "id": "4a9801f9"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "54394f53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54394f53",
        "outputId": "fc62c37e-14c1-46e0-c5ed-04663758fcdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.11.3)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# conda install -c pytorch torchtext\n",
        "# conda install -c pytorch torchdata\n",
        "# conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch\n",
        "\n",
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "878b524f",
      "metadata": {
        "id": "878b524f"
      },
      "outputs": [],
      "source": [
        "# The following libraries are required for running the given code\n",
        "# Please feel free to add any libraries you consider adecuate to complete the assingment.\n",
        "import numpy as np\n",
        "#PyTorch libraries\n",
        "import torch\n",
        "from torchtext.datasets import AG_NEWS\n",
        "# Dataloader library\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "# Libraries to prepare the data\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# neural layers\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# These libraries are suggested to plot confusion matrix\n",
        "# you may use others\n",
        "import scikitplot as skplt\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0LGSeHweU75",
        "outputId": "d806c6f8-144b-4743-b12b-a0f21a9782e7"
      },
      "id": "U0LGSeHweU75",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-mWKcCAfNou",
        "outputId": "30a6ffd2-0d5a-4127-91de-95bee51fb0c8"
      },
      "id": "X-mWKcCAfNou",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.23.5)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchtext) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlNqpWdbfncm",
        "outputId": "dae37e1f-ba3b-440e-c4e7-f1614beae66f"
      },
      "id": "MlNqpWdbfncm",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision torchaudio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7flBgMJbgPrR",
        "outputId": "1d2a6243-7ea0-4b90-ce83-4b5bbeb39548"
      },
      "id": "7flBgMJbgPrR",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3bab55f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bab55f3",
        "outputId": "ae7d95ed-b562-4331-c1e9-ce3091c1948f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d38956d",
      "metadata": {
        "id": "3d38956d"
      },
      "source": [
        "### Get the train and the test datasets and dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9c6b784",
      "metadata": {
        "id": "e9c6b784"
      },
      "source": [
        "Classes:\n",
        "\n",
        "* 1 - World\n",
        "\n",
        "* 2 - Sports\n",
        "\n",
        "* 3 - Business\n",
        "\n",
        "* 4 - Sci/Tech\n",
        "\n",
        "We will convert them to:\n",
        "\n",
        "* 0 - World\n",
        "\n",
        "* 1 - Sports\n",
        "\n",
        "* 2 - Business\n",
        "\n",
        "* 3 - Sci/Tech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "49fbed19",
      "metadata": {
        "id": "49fbed19"
      },
      "outputs": [],
      "source": [
        "train_dataset, test_dataset = AG_NEWS()\n",
        "train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9c372eb9",
      "metadata": {
        "id": "9c372eb9"
      },
      "outputs": [],
      "source": [
        "# Get the tokeniser\n",
        "# tokeniser object\n",
        "tokeniser = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data):\n",
        "    for _, text in data:\n",
        "        yield tokeniser(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "794d0375",
      "metadata": {
        "id": "794d0375"
      },
      "outputs": [],
      "source": [
        "# Build the vocabulary\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_dataset), specials=[\"<unk>\"])\n",
        "#set unknown token at position 0\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b48268d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b48268d4",
        "outputId": "0db7a691-d5b3-4515-a85b-040daa2d3800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['welcome', 'to', 'te3007'] [3314, 4, 0]\n"
          ]
        }
      ],
      "source": [
        "#test tokens\n",
        "tokens = tokeniser('Welcome to TE3007')\n",
        "print(tokens, vocab(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c8c8f6a6",
      "metadata": {
        "id": "c8c8f6a6"
      },
      "outputs": [],
      "source": [
        "NUM_TRAIN = int(len(train_dataset)*0.9)\n",
        "NUM_VAL = len(train_dataset) - NUM_TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8290895e",
      "metadata": {
        "id": "8290895e"
      },
      "outputs": [],
      "source": [
        "train_dataset, val_dataset = random_split(train_dataset, [NUM_TRAIN, NUM_VAL])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cbc75b54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbc75b54",
        "outputId": "af51ec5e-f623-4e19-ee96-82d7372f8c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108000 12000 7600\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset), len(val_dataset), len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ffdbf077",
      "metadata": {
        "id": "ffdbf077"
      },
      "outputs": [],
      "source": [
        "# function passed to the DataLoader to process a batch of data as indicated\n",
        "def collate_batch(batch):\n",
        "    # Get label and text\n",
        "    y, x = list(zip(*batch))\n",
        "\n",
        "    # Create list with indices from tokeniser\n",
        "    x = [vocab(tokeniser(text)) for text in x]\n",
        "    x = [t + ([0]*(max_tokens - len(t))) if len(t) < max_tokens else t[:max_tokens] for t in x]\n",
        "\n",
        "    # Prepare the labels, by subtracting 1 to get them in the range 0-3\n",
        "    return torch.tensor(x, dtype=torch.int32), torch.tensor(y, dtype=torch.int32) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5eb459c7",
      "metadata": {
        "id": "5eb459c7"
      },
      "outputs": [],
      "source": [
        "labels =  [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "max_tokens = 50\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0a55e6ee",
      "metadata": {
        "id": "0a55e6ee"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b98898",
      "metadata": {
        "id": "47b98898"
      },
      "source": [
        "### Let us build our RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "50f20793",
      "metadata": {
        "id": "50f20793"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_SIZE = 300 # complete\n",
        "NEURONS = 256 # complete\n",
        "LAYERS = 2 # complete\n",
        "NUM_CLASSES = 4 # complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0f7f5621",
      "metadata": {
        "id": "0f7f5621"
      },
      "outputs": [],
      "source": [
        "class RNN_Model_1(nn.Module):\n",
        "    def __init__(self, embed_size, hidden, layers, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab),\n",
        "                                            embedding_dim=embed_size)\n",
        "\n",
        "        self.rnn = nn.GRU(input_size = embed_size,\n",
        "                          hidden_size = hidden,\n",
        "                          num_layers=layers,\n",
        "                          batch_first=True,\n",
        "                          bidirectional=True)\n",
        "\n",
        "        self.fc = nn.Linear(in_features = 2 * hidden, out_features = num_classes) # complete output classifier layer using linear layer\n",
        "\n",
        "    def forward(self, x):\n",
        "      vector_embs = self.embedding_layer(x)\n",
        "      y, h = self.rnn(vector_embs)\n",
        "      return self.fc(y[:, -1])\n",
        "        # implement forward pass. This function will be called when executing the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = RNN_Model_1(EMBEDDING_SIZE, NEURONS, LAYERS, NUM_CLASSES)"
      ],
      "metadata": {
        "id": "DAx08NlDuBm7"
      },
      "id": "DAx08NlDuBm7",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "2a42613f",
      "metadata": {
        "code_folding": [],
        "id": "2a42613f"
      },
      "outputs": [],
      "source": [
        "def accuracy(model, loader):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  cost = 0.\n",
        "\n",
        "  with torch.no_grad():\n",
        "      model.eval()\n",
        "      for data in loader:\n",
        "          # Desempaquetamos el dataset en np.arrays y etiquetas\n",
        "          inputs, labels = data[0], data[1]\n",
        "          #outputs = net(images)\n",
        "          xi = inputs.to(device=device)\n",
        "          yi = labels.to(device=device)\n",
        "\n",
        "          yi = yi.type(torch.LongTensor) # <---- Here (casting)\n",
        "          yi = yi.to(device=device)\n",
        "\n",
        "          #Hacemos las predicciones\n",
        "          scores = model(xi)\n",
        "\n",
        "          criterion = F.nll_loss(F.log_softmax(scores, dim=1), yi)\n",
        "\n",
        "          cost +=  criterion.item()\n",
        "          _, pred = torch.max(scores.data, 1)\n",
        "\n",
        "          # Append de resultados\n",
        "          total += pred.size(0)\n",
        "          correct += (pred == yi).sum().item()\n",
        "\n",
        "  # Return del valor total de costo y precision del dataset (loss % accuracy)\n",
        "\n",
        "  return cost/len(data), float(correct)/total"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import long, as_tensor, cat"
      ],
      "metadata": {
        "id": "I_Jfui5M8R8X"
      },
      "id": "I_Jfui5M8R8X",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "5e843e1f",
      "metadata": {
        "code_folding": [],
        "id": "5e843e1f"
      },
      "outputs": [],
      "source": [
        "def train(model, optimiser, epochs=100):\n",
        "  model = model.to(device=device)\n",
        "  train_cost = 0\n",
        "  val_cost = 0.\n",
        "\n",
        "  #Realizamos el entrenamiento cada epcoh, durante el numero definido de epochs en la definicion de hiperparametros.\n",
        "  for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    train_correct_num  = 0.\n",
        "    train_total = 0.\n",
        "    train_cost_acum = 0\n",
        "\n",
        "    #Los entrenamientos se corren sobre el dataset de entrenamiento (no test ni validacion)\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = data[0], data[1]\n",
        "\n",
        "      xi = inputs.to(device=device)\n",
        "      yi = labels.to(device=device)\n",
        "\n",
        "      yi = yi.type(torch.LongTensor) # <---- Here (casting)\n",
        "      yi = yi.to(device=device)\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      scores = model(xi)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      # debemos de reiniciar el gradiente en cada epoch, para no caer en error de memory leak\n",
        "      optimiser.zero_grad()\n",
        "\n",
        "      criterion = nn.NLLLoss()\n",
        "\n",
        "      cost = criterion(scores, yi)\n",
        "\n",
        "      # funcion de costo\n",
        "      cost.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "      _, pred = torch.max(scores.data, 1)\n",
        "\n",
        "      train_correct_num += (pred == yi).sum().item()\n",
        "      train_total += scores.size(0)\n",
        "\n",
        "      train_cost_acum += cost.item()\n",
        "\n",
        "    #Calculamos el costo y la precision despues de cada epoch entrenada\n",
        "    # Debemos de hacer la evaluacion en el dataset de validacion (no el de entrenamiento)\n",
        "    # El dataset de test se deberia de usar despues, para hacer la matriz de confusion.\n",
        "    # Utilizar el mismo dataset durante el calculo de precision y perdida conllevaria a un problema\n",
        "    # de memory leak y no seria correcto.\n",
        "    val_cost, val_acc = accuracy(model, val_loader)\n",
        "\n",
        "    ### Train total -> tamano del dataset entrenado, en este caso 5000\n",
        "    ### train_correct_num  -> Cantidad de items correctamente clasificados\n",
        "    ### train_acc  -> Precision del modelo. Debe de tender a 1.\n",
        "    ### train_cost  -> Funcion de costo (mayormente conocida como loss). Error acumulado. Debe de tender a 0\n",
        "    train_acc = float(train_correct_num)/train_total\n",
        "    train_cost = train_cost_acum/i\n",
        "\n",
        "  # Vamos a monitorear la mejora cada 3 epochs\n",
        "  # esto con el fin de lograr seleccionar el numero apropiado de epochs necesarios para lograr\n",
        "  # el accuracy solicitado (evitar epcohs de sobra)\n",
        "    if epoch%3 == 0:\n",
        "      print(f'Epoch:{epoch}, train cost: {train_cost:.6f}, val cost: {val_cost:.6f},'\n",
        "                      f' train acc: {train_acc:.4f}, val acc: {val_acc:4f},'\n",
        "                      f' lr: {optimiser.param_groups[0][\"lr\"]:.6f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "87775b29",
      "metadata": {
        "id": "87775b29"
      },
      "outputs": [],
      "source": [
        "epochs = 40\n",
        "lr = 0.0001\n",
        "# instantiate model\n",
        "rnn_model = RNN_Model_1(EMBEDDING_SIZE, NEURONS, LAYERS, NUM_CLASSES)\n",
        "optimiser = torch.optim.Adam(gru_model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "aec12a1b",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "aec12a1b",
        "outputId": "6d2d31cf-9352-4eff-b32b-3e6a22ffd597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0, train cost: -592.317288, val cost: 39.001468, train acc: 0.2499, val acc: 0.251167, lr: 0.000100\n",
            "Epoch:3, train cost: -657.033699, val cost: 38.716620, train acc: 0.2499, val acc: 0.251167, lr: 0.000100\n",
            "Epoch:6, train cost: -721.757023, val cost: 38.748548, train acc: 0.2499, val acc: 0.251167, lr: 0.000100\n",
            "Epoch:9, train cost: -786.477434, val cost: 38.673606, train acc: 0.2499, val acc: 0.251167, lr: 0.000100\n",
            "Epoch:12, train cost: -851.189968, val cost: 38.971161, train acc: 0.2499, val acc: 0.251167, lr: 0.000100\n",
            "Epoch:15, train cost: -915.903621, val cost: 38.714205, train acc: 0.2499, val acc: 0.251167, lr: 0.000100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-8eb0d64d0838>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-cee91650deb6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimiser, epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0;31m# funcion de costo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m       \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(gru_model, optimiser=optimiser,  epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a3ef175",
      "metadata": {
        "id": "7a3ef175"
      },
      "outputs": [],
      "source": [
        "print(f'{accuracy(gru_model, test_loader):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed30693d",
      "metadata": {
        "id": "ed30693d"
      },
      "outputs": [],
      "source": [
        "def sample_text(model, loader):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "534f0220",
      "metadata": {
        "id": "534f0220"
      },
      "outputs": [],
      "source": [
        "sample_text(rnn_model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb38e093",
      "metadata": {
        "id": "bb38e093"
      },
      "outputs": [],
      "source": [
        "# create confusion matrix\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d73f69",
      "metadata": {
        "id": "e7d73f69"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5327e204",
      "metadata": {
        "id": "5327e204"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc921f9",
      "metadata": {
        "id": "7bc921f9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed62b0d5",
      "metadata": {
        "id": "ed62b0d5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c82cfd3",
      "metadata": {
        "id": "1c82cfd3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}